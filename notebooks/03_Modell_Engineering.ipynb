{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# MLOps Workshop: Modell-Engineering und Training\n",
    "\n",
    "## EinfÃ¼hrung\n",
    "In diesem Notebook werden wir uns mit dem Modell-Engineering und Training fÃ¼r unser Customer Churn Prediction Projekt beschÃ¤ftigen. Wir werden MLflow fÃ¼r das Experiment-Tracking verwenden und verschiedene Modelle evaluieren.\n",
    "\n",
    "## Lernziele\n",
    "Nach Abschluss dieses Notebooks werden Sie:\n",
    "- Verstehen, wie man MLflow fÃ¼r Experiment-Tracking einsetzt\n",
    "- Verschiedene Modelle mit unterschiedlichen Hyperparametern trainieren kÃ¶nnen\n",
    "- Best Practices fÃ¼r Modell-Evaluierung kennen\n",
    "- Wissen, wie man Modelle im MLflow Model Registry registriert\n",
    "\n",
    "## 1. Setup und Daten laden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BenÃ¶tigte Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# MLflow Tracking lokal einrichten (ohne Server)\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden und vorbereiten\n",
    "processed_data = pd.read_csv('../data/processed/telco_customer_churn_processed.csv')\n",
    "\n",
    "# Numerische Spalten standardisieren\n",
    "numeric_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "scaler = StandardScaler()\n",
    "processed_data[numeric_columns] = scaler.fit_transform(processed_data[numeric_columns])\n",
    "\n",
    "# One-Hot-Encoding fÃ¼r kategorische Variablen\n",
    "categorical_columns = processed_data.select_dtypes(include=['object']).columns\n",
    "categorical_columns = [col for col in categorical_columns if col not in ['Churn', 'customerID']]\n",
    "\n",
    "# One-Hot-Encoding anwenden\n",
    "X = pd.get_dummies(processed_data.drop(['Churn', 'customerID'], axis=1), columns=categorical_columns)\n",
    "y = processed_data['Churn']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. MLflow Experiment erstellen\n",
    "\n",
    "### Aufgabe 1\n",
    "Erstellen Sie ein neues MLflow Experiment fÃ¼r unser Churn-Vorhersage-Projekt. Setzen Sie einen aussagekrÃ¤ftigen Namen und eine Beschreibung.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "# MLflow Experiment erstellen\n",
    "experiment_name = \"customer_churn_prediction\"\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Experiment-Details ausgeben\n",
    "print(f\"Experiment Name: {experiment_name}\")\n",
    "print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3. Modell-Training mit MLflow Tracking\n",
    "\n",
    "### Aufgabe 2\n",
    "Implementieren Sie eine Funktion, die ein Modell trainiert und die wichtigsten Metriken mit MLflow trackt.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name, params=None):\n",
    "    \"\"\"\n",
    "    Trainiert ein Modell und trackt die Ergebnisse mit MLflow\n",
    "    \"\"\"\n",
    "    with mlflow.start_run() as run:\n",
    "        # Parameter loggen\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        \n",
    "        # Modell trainieren\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Vorhersagen\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Metriken berechnen\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "        \n",
    "        # Metriken loggen\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Modell loggen\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # Feature Importance Plot erstellen und loggen\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "            plt.title(f'Feature Importance - {model_name}')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Plot als Artefakt speichern\n",
    "            plt.savefig('feature_importance.png')\n",
    "            mlflow.log_artifact('feature_importance.png')\n",
    "            plt.close()\n",
    "            \n",
    "        return run.info.run_id, {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Aufgabe 3\n",
    "Trainieren Sie verschiedene Modelle mit unterschiedlichen Hyperparametern und tracken Sie die Ergebnisse.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "# Random Forest mit verschiedenen Hyperparametern\n",
    "rf_params_list = [\n",
    "    {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 2,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    {\n",
    "        'n_estimators': 200,\n",
    "        'max_depth': 15,\n",
    "        'min_samples_split': 5,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    {\n",
    "        'n_estimators': 300,\n",
    "        'max_depth': None,\n",
    "        'min_samples_split': 10,\n",
    "        'random_state': 42\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for params in rf_params_list:\n",
    "    model = RandomForestClassifier(**params)\n",
    "    run_id, metrics = train_and_evaluate_model(\n",
    "        model, X_train, X_test, y_train, y_test,\n",
    "        model_name=\"RandomForest\",\n",
    "        params=params\n",
    "    )\n",
    "    results.append({\n",
    "        'run_id': run_id,\n",
    "        'params': params,\n",
    "        'metrics': metrics\n",
    "    })\n",
    "\n",
    "# Ergebnisse als DataFrame anzeigen\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'run_id': r['run_id'],\n",
    "        **r['params'],\n",
    "        **r['metrics']\n",
    "    } for r in results\n",
    "])\n",
    "print(\"\\nModell-Vergleich:\")\n",
    "print(results_df)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modell im MLflow Model Registry registrieren\n",
    "\n",
    "### Aufgabe 4\n",
    "WÃ¤hlen Sie das beste Modell aus und registrieren Sie es im MLflow Model Registry.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "# Bestes Modell anhand des F1-Scores auswÃ¤hlen\n",
    "best_run = max(results, key=lambda x: x['metrics']['f1_score'])\n",
    "best_run_id = best_run['run_id']\n",
    "\n",
    "# Modell im Registry registrieren\n",
    "model_name = \"customer_churn_predictor\"\n",
    "model_version = mlflow.register_model(\n",
    "    f\"runs:/{best_run_id}/model\",\n",
    "    model_name\n",
    ")\n",
    "\n",
    "print(f\"Model '{model_name}' wurde als Version {model_version.version} registriert\")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modell-Staging und Deployment vorbereiten\n",
    "\n",
    "### Aufgabe 5\n",
    "Setzen Sie das registrierte Modell auf \"Staging\" und dokumentieren Sie die Modell-Details.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Modell auf \"Staging\" setzen\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version.version,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=True\n",
    ")\n",
    "\n",
    "# Modell-Details dokumentieren\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version.version,\n",
    "    description=f\"\"\"\n",
    "    Customer Churn Prediction Model v{model_version.version}\n",
    "    \n",
    "    - Modelltyp: Random Forest\n",
    "    - Training durchgefÃ¼hrt am: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "    - Beste Parameter: {best_run['params']}\n",
    "    - Performance Metriken:\n",
    "        - Accuracy: {best_run['metrics']['accuracy']:.4f}\n",
    "        - Precision: {best_run['metrics']['precision']:.4f}\n",
    "        - Recall: {best_run['metrics']['recall']:.4f}\n",
    "        - F1-Score: {best_run['metrics']['f1_score']:.4f}\n",
    "    \"\"\"\n",
    ")\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hausaufgaben und weiterfÃ¼hrende Ãœbungen\n",
    "1. Experimentieren Sie mit weiteren Modelltypen (z.B. XGBoost, LightGBM)\n",
    "2. Implementieren Sie eine Cross-Validation in den Training-Prozess\n",
    "3. Erweitern Sie das Feature Importance Plot um weitere Visualisierungen\n",
    "4. FÃ¼gen Sie Custom Tags zu den MLflow Runs hinzu\n",
    "5. Implementieren Sie eine automatische Modellversionierung basierend auf Performance-Metriken\n",
    "\n",
    "## NÃ¤chste Schritte\n",
    "- Fahren Sie mit dem Deployment-Notebook fort\n",
    "- Lernen Sie, wie man das Modell mit FastAPI bereitstellt\n",
    "- Implementieren Sie Monitoring fÃ¼r das deployte Modell\n",
    "\n",
    "## Hilfreiche MLflow-Befehle\n",
    "```bash\n",
    "# MLflow UI starten\n",
    "mlflow ui\n",
    "\n",
    "# Experiments auflisten\n",
    "mlflow experiments list\n",
    "\n",
    "# Run Details anzeigen\n",
    "mlflow runs describe <run-id>\n",
    "\n",
    "# Modell laden\n",
    "mlflow models load runs:/<run-id>/model\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
