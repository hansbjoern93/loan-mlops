{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Workshop: Model Packaging und Containerisierung\n",
    "\n",
    "## EinfÃ¼hrung\n",
    "In diesem Notebook lernen wir, wie wir unseren Customer Churn Predictor in einen Docker Container verpacken. Wir werden sowohl das trainierte Modell als auch die FastAPI-Anwendung containerisieren.\n",
    "\n",
    "## Lernziele\n",
    "Nach Abschluss dieses Notebooks kÃ¶nnen Sie:\n",
    "- Ein ML-Modell fÃ¼r die Produktion vorbereiten\n",
    "- Eine FastAPI-Anwendung containerisieren\n",
    "- Best Practices fÃ¼r ML-Model-Serving implementieren\n",
    "- Docker-Container fÃ¼r ML-Anwendungen erstellen und testen\n",
    "\n",
    "## Prerequisites\n",
    "- Abgeschlossenes Modelltraining und -evaluierung (Notebooks 03 und 04)\n",
    "- Docker auf dem System installiert\n",
    "- FastAPI Backend implementiert\n",
    "\n",
    "## 1. Modell-Export und Verifikation\n",
    "\n",
    "Zuerst laden wir unsere benÃ¶tigten Bibliotheken:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# MLflow Setup\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "client = MlflowClient()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Modell laden und Ã¼berprÃ¼fen\n",
    "Verifizieren Sie das trainierte Modell und seine Features.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "# Modell laden\n",
    "model_name = \"customer_churn_predictor\"\n",
    "model_version = client.get_latest_versions(model_name, stages=[\"Staging\"])[0]\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{model_version.run_id}/model\")\n",
    "\n",
    "# Features Ã¼berprÃ¼fen\n",
    "print(\"Modell Features:\", model.feature_names_in_)\n",
    "\n",
    "# Beispiel-Prediction durchfÃ¼hren\n",
    "test_data = pd.DataFrame({\n",
    "    'gender': [1],\n",
    "    'tenure': [12],\n",
    "    'MonthlyCharges': [89.9],\n",
    "    'TotalCharges': [1078.8],\n",
    "    'AvgCostPerService': [29.97],\n",
    "    'CustomerAge': [42]\n",
    "})\n",
    "\n",
    "prediction = model.predict_proba(test_data)\n",
    "print(\"\\nTest Prediction:\", prediction[:, 1])\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell laden\n",
    "model_name = \"customer_churn_predictor\"\n",
    "model_version = client.get_latest_versions(model_name, stages=[\"Staging\"])[0]\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{model_version.run_id}/model\")\n",
    "\n",
    "# Features Ã¼berprÃ¼fen\n",
    "print(\"Modell Features:\", model.feature_names_in_)\n",
    "\n",
    "# Beispiel-Prediction durchfÃ¼hren\n",
    "test_data = pd.DataFrame({\n",
    "    'gender': [1],\n",
    "    'tenure': [12],\n",
    "    'MonthlyCharges': [89.9],\n",
    "    'TotalCharges': [1078.8],\n",
    "    'AvgCostPerService': [29.97],\n",
    "    'CustomerAge': [42]\n",
    "})\n",
    "\n",
    "prediction = model.predict_proba(test_data)\n",
    "print(\"\\nTest Prediction:\", prediction[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API-Dateien vorbereiten\n",
    "\n",
    "### Aufgabe 2: Erstellen Sie die requirements.txt\n",
    "Erstellen Sie eine requirements.txt mit allen benÃ¶tigten Paketen.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```bash\n",
    "# requirements.txt\n",
    "fastapi==0.104.1\n",
    "uvicorn==0.24.0\n",
    "pandas==2.1.3\n",
    "numpy==1.26.2\n",
    "scikit-learn==1.3.2\n",
    "mlflow==2.8.1\n",
    "pydantic==2.5.2\n",
    "python-multipart==0.0.6\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Projektstruktur erstellen\n",
    "Erstellen Sie die benÃ¶tigte Verzeichnisstruktur.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```bash\n",
    "project_root/\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â””â”€â”€ api/\n",
    "â”‚       â”œâ”€â”€ main.py\n",
    "â”‚       â””â”€â”€ test_main.py\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â””â”€â”€ model/\n",
    "â”œâ”€â”€ notebooks/\n",
    "â”‚   â””â”€â”€ mlruns/\n",
    "â”œâ”€â”€ Dockerfile\n",
    "â”œâ”€â”€ docker-compose.yml\n",
    "â””â”€â”€ requirements.txt\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Docker Configuration\n",
    "\n",
    "### Aufgabe 4: Dockerfile erstellen\n",
    "Erstellen Sie ein Dockerfile fÃ¼r die FastAPI-Anwendung.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```dockerfile\n",
    "# Base image\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy requirements first for better caching\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Install dependencies\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy the rest of the application\n",
    "COPY src/api /app/api\n",
    "COPY notebooks/mlruns /app/mlruns\n",
    "\n",
    "# Environment variables\n",
    "ENV PYTHONPATH=/app\n",
    "ENV MODEL_PATH=/app/mlruns\n",
    "\n",
    "# Switch to non-root user\n",
    "RUN useradd -m appuser\n",
    "USER appuser\n",
    "\n",
    "# Command to run the application\n",
    "CMD [\"uvicorn\", \"api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 5: Docker Compose erstellen\n",
    "Erstellen Sie eine docker-compose.yml fÃ¼r einfaches Deployment.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```yaml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  churn-predictor:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    volumes:\n",
    "      - ./notebooks/mlruns:/app/mlruns\n",
    "    environment:\n",
    "      - MODEL_PATH=/app/mlruns\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Container Build und Test\n",
    "\n",
    "### Aufgabe 6: Container erstellen und testen\n",
    "Bauen und testen Sie den Docker Container.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```bash\n",
    "# Container bauen\n",
    "docker build -t churn-predictor:latest .\n",
    "\n",
    "# Container starten\n",
    "docker run -p 8000:8000 churn-predictor:latest\n",
    "\n",
    "# Test mit curl\n",
    "curl -X 'POST' \\\n",
    "  'http://localhost:8000/predict' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "    \"data\": [{\n",
    "        \"gender\": 1,\n",
    "        \"tenure\": 12,\n",
    "        \"MonthlyCharges\": 89.9,\n",
    "        \"TotalCharges\": 1078.8,\n",
    "        \"AvgCostPerService\": 29.97,\n",
    "        \"CustomerAge\": 42\n",
    "    }]\n",
    "}'\n",
    "```\n",
    "\n",
    "Python-Code zum Testen:\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Test-Daten\n",
    "test_data = {\n",
    "    \"data\": [{\n",
    "        \"gender\": 1,\n",
    "        \"tenure\": 12,\n",
    "        \"MonthlyCharges\": 89.9,\n",
    "        \"TotalCharges\": 1078.8,\n",
    "        \"AvgCostPerService\": 29.97,\n",
    "        \"CustomerAge\": 42\n",
    "    }]\n",
    "}\n",
    "\n",
    "# API-Request\n",
    "response = requests.post(\n",
    "    'http://localhost:8000/predict',\n",
    "    json=test_data\n",
    ")\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response:\", response.json())\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Testing\n",
    "\n",
    "### Aufgabe 7: Last- und Performance-Tests\n",
    "Implementieren Sie einfache Last-Tests.\n",
    "\n",
    "<details>\n",
    "<summary>ðŸ‘‰ LÃ¶sung anzeigen</summary>\n",
    "\n",
    "```python\n",
    "import time\n",
    "import concurrent.futures\n",
    "import statistics\n",
    "\n",
    "def make_prediction_request():\n",
    "    \"\"\"Einzelne Prediction durchfÃ¼hren\"\"\"\n",
    "    response = requests.post(\n",
    "        'http://localhost:8000/predict',\n",
    "        json=test_data\n",
    "    )\n",
    "    return response.elapsed.total_seconds()\n",
    "\n",
    "def run_load_test(num_requests=100, concurrent_requests=10):\n",
    "    \"\"\"Load Test durchfÃ¼hren\"\"\"\n",
    "    response_times = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_requests) as executor:\n",
    "        futures = [executor.submit(make_prediction_request) for _ in range(num_requests)]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            response_times.append(future.result())\n",
    "    \n",
    "    print(f\"\\nLoad Test Results (n={num_requests}):\")\n",
    "    print(f\"Mean response time: {statistics.mean(response_times):.3f}s\")\n",
    "    print(f\"Median response time: {statistics.median(response_times):.3f}s\")\n",
    "    print(f\"95th percentile: {np.percentile(response_times, 95):.3f}s\")\n",
    "\n",
    "# Load Test ausfÃ¼hren\n",
    "run_load_test()\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hausaufgaben und weiterfÃ¼hrende Ãœbungen\n",
    "1. Implementieren Sie ein Multi-Stage Docker Build\n",
    "2. FÃ¼gen Sie Prometheus Metriken hinzu\n",
    "3. Implementieren Sie ein Blue-Green Deployment\n",
    "4. Erstellen Sie ein Kubernetes Deployment Manifest\n",
    "5. Implementieren Sie automatische Skalierung\n",
    "\n",
    "## NÃ¤chste Schritte\n",
    "- Deployment in einer Cloud-Umgebung\n",
    "- Implementierung von Monitoring und Logging\n",
    "- CI/CD Pipeline aufsetzen\n",
    "- Kubernetes Deployment vorbereiten\n",
    "\n",
    "## Hilfreiche Befehle\n",
    "\n",
    "```bash\n",
    "# Docker\n",
    "docker build -t churn-predictor .\n",
    "docker run -p 8000:8000 churn-predictor\n",
    "docker ps\n",
    "docker logs <container_id>\n",
    "\n",
    "# Docker Compose\n",
    "docker-compose up -d\n",
    "docker-compose logs\n",
    "docker-compose down\n",
    "\n",
    "# Curl Tests\n",
    "curl http://localhost:8000/health\n",
    "curl http://localhost:8000/model-info\n",
    "```\n",
    "\n",
    "## ZusÃ¤tzliche Hinweise\n",
    "- Verwenden Sie immer spezifische Versionen in requirements.txt\n",
    "- Implementieren Sie Health Checks fÃ¼r Container Orchestration\n",
    "- Nutzen Sie Docker Layer Caching effektiv\n",
    "- Minimieren Sie die Image-GrÃ¶ÃŸe\n",
    "- Beachten Sie Security Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
